CONTENTS OF THIS FILE
---------------------------
* Introduction
* Requirements & Installation
* Packages needed
* Setting up PythonGenericServer
* Running PythonGenericServer
* Setting up NGINX + PythonGenericServer
---------------------------

1. INTRODUCTION
---------------------------

This is the README for the python generic server, built using Flask.

>>>>README.txt was last updated June 1, 2016<<<<

2. INSTALLATION
---------------------------
Note: This was last tested on an AWS instance (Ubuntu 14.04).

Following packages will be needed:
---------------------------

- NVIDIA DRIVER 358.16			-dlib 18.18
- NVIDIA cuda toolkit 7.5.17	
- OpenCV3.0
- cudNN4

A. Install NVIDIA Drivers:
Reference: https://github.com/BVLC/caffe/wiki/Install-Caffe-on-EC2-from-scratch-(Ubuntu,-CUDA-7,-cuDNN)

1. Create a directory to pull all packages into. 
	a. >> mkdir /home/ubuntu/stuff
2. Download the following files from NVIDIA and put into new folder
	a. >> mkdir /home/ubuntu/stuff/nvidia_installers
	b. >> cd /home/ubuntu/stuff/nvidia_installers
	c. >> mv cuda_7.5.18_linux.run /home/ubuntu/stuff/nvidia_installers
	d. >> mv NVIDIA-Linux-x86_64-358.16.run /home/ubuntu/stuff/nvidia_installers
3. Update and install dependencies
	a. >> sudo apt-get update && sudo apt-get upgrade
	b. >> sudo apt-get install build-essential
4. Update linux image to be compatible with NVIDIA's driver
	a. >> sudo apt-get install linux-image-extra-virtual
5. Disable nouveau since it conflicts with NVIDIA's kernel module
	a. >> echo -e "blacklist nouveau\nblacklist lbm-nouveau\noptions nouveau modeset=0\nalias nouveau off\nalias lbm-nouveau off" |sudo tee --append /etc/modprobe 
	b. >> echo options nouveau modeset=0 | sudo tee -a /etc/modprobe.d/nouveau-kms.conf
	c. >> sudo update-initramfs -u
	d. >> sudo reboot
6. After reboot:
	a. >> sudo apt-get install linux-source
	b. >> sudo apt-get install linux-headers-`uname -r`
7. Install cuda toolkit
	a. >> sudo modprobe nvidia
	b. >> sudo apt-get install build-essential
	c. >> sudo ./cuda_7.5.18_linux.run
		i. When the license agreement appears, press "q" so you don't have to scroll down.
	   ii. Accept the EULA.
	  iii. If asked, do you want to install 352* driver? Enter yes!!!
	   iv. Use the default path by pressing enter.
	    v. If asked, do you want to install toolkit examples? Enter yes!!!
	   vi. Would you like to create a symbolic link? Enter yes.
	  vii. It will now install CUDA.
	d. >> vi ~/.bashrc and add the following lines [to save & quit vi ":wq"]

export PATH=$PATH:/usr/local/cuda-7.5/bin
export LD_LIBRARY_PATH=/usr/local/cuda-7.5/lib64

	e. >> source ~/.bashrc

8. Remove the NVIDIA 352 driver and instead install NVIDIA 358 driver
	a. >> sudo apt-get remove --purge nvidia-*
	b. >> sudo apt-get install ubuntu-desktop
	c. >> sudo rm /etc/X11/xorg.conf
	d. >> echo 'nouveau' | sudo tee -a /etc/modules
	e. >> sudo reboot
	f. >> sudo service lightdm stop
	g. >> sudo ./NVIDIA-Linux-x86_64-358.16.run
		i. When the license agreement appears, press "q" so you don't have to scroll down.
	   ii. Accept the license agreement.
	  iii. If you see: "nvidia-installer was forced to guess the X library path '/usr/lib' and X module path ..." go ahead and click OK.
	   iv. If you see "The CC version check failed" then click "Ignore CC version check".
	    v. It may ask you about 32-bit libraries, select yes to install them.
	   vi. It will ask you about running nvidia-xconfig to update your X configuration file. Select no.

9. Check both NVIDIA DRIVER & CUDA TOOLKIT
	a. >> nvidia-smi

+------------------------------------------------------+                       
| NVIDIA-SMI 358.16     Driver Version: 358.16         |                       
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  GRID K520           Off  | 0000:00:03.0     Off |                  N/A |
| N/A   38C    P0    42W / 125W |     11MiB /  4095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  GRID K520           Off  | 0000:00:04.0     Off |                  N/A |
| N/A   35C    P0    41W / 125W |     11MiB /  4095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  GRID K520           Off  | 0000:00:05.0     Off |                  N/A |
| N/A   39C    P0    42W / 125W |     11MiB /  4095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  GRID K520           Off  | 0000:00:06.0     Off |                  N/A |
| N/A   35C    P0    37W / 125W |     11MiB /  4095MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID  Type  Process name                               Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+

	b. >> nvcc --version

nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2015 NVIDIA Corporation
Built on Tue_Aug_11_14:27:32_CDT_2015
Cuda compilation tools, release 7.5, V7.5.17

B. Install OpenCV3.0

1. 	>> sudo apt-get update
2.	>> sudo apt-get upgrade
3. 	>> sudo apt-get install build-essential cmake git pkg-config git
4. 	>> sudo apt-get install libjpeg8-dev libtiff4-dev libjasper-dev libpng12-dev
5. 	>> sudo apt-get install libgtk2.0-dev
6. 	>> sudo apt-get install libavcodec-dev libavformat-dev libswscale-dev libv4l-dev
7. 	>> sudo apt-get install libatlas-base-dev gfortran
8. 	>> wget https://bootstrap.pypa.io/get-pip.py
9. 	>> sudo python get-pip.py
10. >> sudo apt-get install python2.7-dev
11. >> sudo pip install numpy
12.	>> cd ~/stuff/
13.	>> cd opencv
14. >> git checkout 3.0.0
15.	>> cd ../
16.	>> git clone https://github.com/Itseez/opencv_contrib.git
17.	>> cd opencv_contrib
18.	>> git checkout 3.0.0
19.	>> cd ../
20.	>> cd ~/opencv
21.	>> mkdir build
22.	>> cd build
23. Note: check opencv_extra_modules_path & python paths
	>> cmake -D CMAKE_BUILD_TYPE=RELEASE \ -D CMAKE_INSTALL_PREFIX=/usr/local \ -D INSTALL_C_EXAMPLES=ON \ -D INSTALL_PYTHON_EXAMPLES=ON \ -D OPENCV_EXTRA_MODULES_PATH=/home/ubuntu/stuff/opencv_contrib/modules \ -D BUILD_EXAMPLES=ON \ -D WITH_FFMPEG=OFF \ -D WITH_CUDA=ON \ -D WITH_QT=ON \ -D WITH_OPENGL=ON \ -D_FORCE_VTK=ON \ -D WITH_TBB=ON \ -D WITH_GDAL=ON \ -D BUILD_opencv_legacy=OFF \ -D PYTHON_INCLUDE_DIRS=/usr/include/python2.7 \ -D PYTHON_INCLUDE_DIR2=/usr/include/python2.7 \ -D PYTHON_LIBRARIES =/usr/lib/x86_64-linux-gnu/libpython2.7.so \ -D PYTHON_PACKAGES_PATH=/usr/local/lib/python2.7/dist-packages/\ -D PYTHON2_LIBRARIES =/usr/lib/x86_64-linux-gnu/libpython2.7.so ..
24. >> make
25. >> sudo cp /home/ubuntu/stuff/opencv/build/lib/cv2.so /usr/local/lib/python2.7/dist-packages/
26.	>> sudo make install 
27.	>> sudo ldconfig
28.	>> sudo vi /etc/ld.so.conf.d/opencv.conf [to save & quit vi ":wq"]
		--> Add in line 
			i. /usr/local/lib
29.	>> sudo ldconfig
30. To test if installed correctly:
		i. >> python
	   ii. >> import cv2
	  iii. >> cv2.__version__

C. Install cudNN4

	a. >> cd /home/ubuntu/stuff/cudNN_v4
2. >> sudo cp lib64/* /usr/local/cuda/lib64/
3. >> sudo cp include/cudnn.h /usr/local/cuda/include/
4. Might need to re-make symbolic links
	i. >> cd /usr/local/cuda/lib64  
   ii. >> sudo rm libcudnn.so.4 libcudnn.so
  iii. >> sudo ln -s libcudnn.so.4.0.7 libcudnn.so.4
   iv.  >> sudo ln -s libcudnn.so.4 libcudnn.so

D. Install dLIB18.18

or download from git
	a. >> cd /home/ubuntu/stuff/
	b. >> git clone https://github.com/davisking/dlib
	c. >> cd dlib
2. >> sudo apt-get install libx11-dev
3. >> cd examples
4. >> mkdir build
5. >> cd build
6. >> cmake .. 
7. >> cmake --build .
8. >> cd ../
9. >> sudo apt-get install --no-install-recommends libboost-all-dev [download boost!]
10. >> sudo python setup.py install
11. >> cd dlib/test
12. >> mkdir build
13. >> cd build
14. >> cmake ..
15. >> cmake --build . --config Release
16. >> ./dtest --runall

E. Install GumGumCaffe

2. >> sudo apt-get install libprotobuf-dev libleveldb-dev libsnappy-dev libopencv-dev libhdf5-serial-dev protobuf-compiler
3. >> sudo apt-get install --no-install-recommends libboost-all-dev
4. >> sudo apt-get install libgflags-dev libgoogle-glog-dev liblmdb-dev 
5. Create Makefile.config
	a. >> cd /home/ubuntu/stuff/caffe/caffe-fast-rcnn
	b. >> cp Makefile.config.example Makefile.config
	c. >> vi Makefile.config
		i. Uncomment the line: USE_CUDNN := 1
	   ii. Uncomment the line: WITH_PYTHON_LAYER := 1
	  iii. Uncomment the line: USE_PKG_CONFIG := 1
	   iv. Check that the CUDA_DIR correctly points to CUDA installation directory
	    v. Check that the PYTHON_DIR correctly points to Python.h and numpy/arrayobject.h location
6. >> sudo make -j6 && sudo make pycaffe -j6

***NOTE*********************************************************************************
If you see this error " cannot find -lippicv " , follow these steps, else skip this note:
a) Go to opencv root folder, cd $OpenCv_ROOT/3rdparty/ippicv/downloads/linux-808b791a6eac9ed78d32a7666804320e/
b) tar -zxf *the file in this directory*
c) navigate to the "lib/intel64" directory in the newly extracted folder.
d) Copy the libippicv.a to /usr/local/lib
*****************************************************************************************


7. >> cd ../lib
	a. >> sudo apt-get install cython
	b. >> vi /home/ubuntu/stuff/caffe/caffe-fast-rcnn/src/caffe/layers/roi_pooling_layer.cu
	c. Comment out the following line in roi_pooling_layer.cu
		i. //CUDA_POST_KERNEL_CHECK; [line 91]
	b. >> sudo make

3. SETTING UP PythonGenericServer
---------------------------
2. >> cd /home/ubuntu/stuff/pythongenericserver
3. >> mkdir models
4. Make a folder with the model name - for example:
	a. >> mkdir models/murals
	b. Download epoch into murals folder and uncompress the file
		i. Go to DIGITS, select the epoch desired, download as compressed file 
	   ii. ex. >> cd models/murals
	  iii. ex. >> tar -xvzf 20160412-085835-5ee8_epoch_13.0.mural.tar.gz
5. >> sudo pip install scikit-image
6. >> sudo apt-get install python-scipy
7. >> sudo apt-get install python-matplotlib
8. >> sudo pip install protobuf
9. Edit file name in murals folder to have the following convention
	a. >> snapshot_iter_2078850.caffemodel model.caffemodel
	b. These files should also be present from the model 
		i. labels.txt
	   ii. model.caffemodel
	  iii. deploy.prototxt
	   iv. mean.npy <-- will be created after step 12.
10. >> sudo pip install flask
11. >> sudo apt-get install python-pandas
12. Run python script 
	a. >> cd /home/ubuntu/stuff/pythongenericserver
	b. >> python convertmean.py models/murals/mean.binaryproto models/murals/mean.npy
13. >> sudo pip install boto
14. >> sudo pip install botocore
15. >> sudo pip install boto3
16. Edit the paths in _init_paths.py to ensure correct directories are being used

4. RUNNING PythonGenericServer
---------------------------

1. For taking a request
	a. >> python webapp.py --port 5000 --model rcnnFaster --type RCNN
	b. >> python webapp.py --port 5000 --model crf-rnn --type SEGMENTER
	c. For murals: 
		i. >> python webapp.py --port 5000 --model murals --type CNN --topoutput 3
	d. For GumFace
		ii. >> python webapp.py --port 5000 --model GumFace --type CNN --preprocess face

2. For pulling a request
	a. >> python webapp.py --port 5000 --model rcnnFaster --type RCNN --pullrequest
	b. For murals:
		i. >> python webapp.py --port 5000 --model murals --type CNN --topoutput 1 --pullrequest

3. On another terminal - send request using:
	a. >> curl -i "http://localhost:5000/?image=www.celebitchy.com/wp-content/uploads/2011/07/wenn3436540.jpg"
	b. >> ./hitserver [run script with mutliple curl commands]
	c. >> For local file:
		>> curl "http://localhost:5000/filepath/to/image"
		>> ex. curl -v "http://localhost:5000/home/projects/pythongenericserver/wenn3436540.jpg"

4. To quit server
	a. Hit CTRL+C twice
        
5. SETTING UP with NGINX + PythonGenericServer
---------------------------

1. >> sudo apt-get install nginx
2. >> cd /etc/ld.so.conf.d
	a. Make new file: >> vi nvidia.conf [to save & quit vi ":wq"]
		i. Add: /usr/local/cuda/lib64 
	b. Check to make sure there is a opencv.conf
		i. Add /usr/local/lib
	c. Check to make sure there is a libc.conf
		i. Add /usr/local/lib
3. In this directory
	a. >> cd /etc/init.d
	b. Copy "imaging" file from Face Detector 
	c. The loops are created to distribute 20 servers equally on the available 4 GPUs

**************
########## Filename: imaging #########
#!/bin/bash

MURAL_START_A=9000
MURAL_FINISH_A=9004

MURAL_START_B=9005
MURAL_FINISH_B=9009

MURAL_START_C=9010
MURAL_FINISH_C=9014

MURAL_START_D=9015
MURAL_FINISH_D=9019

IPADDR=`ifconfig eth0 | awk '/inet addr/{print substr($2,6)}'`

LOGDIR=/var/log/imaging

if [ ! -d ${LOGDIR} ]
then
	mkdir ${LOGDIR}
fi

killmural () {
	   sudo ps -ef | grep webapp.py | grep -v grep | awk '{print $2}' | xargs kill -9
}

startmural () {
        cd /home/ubuntu/stuff/pythongenericserver/
        for ((i=${MURAL_START_A};i<=${MURAL_FINISH_A};i++))
        do
		/usr/bin/nohup python webapp.py --port ${i} --model murals --type CNN --deviceid 0 >> ${LOGDIR}/mural-${i}.log 2>&1 &
                /bin/echo "Starting mural-server on port ${i}...${IPADDR}"
                sleep 5
        done

        for ((i=${MURAL_START_B};i<=${MURAL_FINISH_B};i++))
        do
                /usr/bin/nohup python webapp.py --port ${i} --model murals --type CNN --deviceid 1 >> ${LOGDIR}/mural-${i}.log 2>&1 &
                /bin/echo "Starting mural-server on port ${i}...${IPADDR}"
                sleep 5
        done

        for ((i=${MURAL_START_C};i<=${MURAL_FINISH_C};i++))
        do
                /usr/bin/nohup python webapp.py --port ${i} --model murals --type CNN --deviceid 2 >> ${LOGDIR}/mural-${i}.log 2>&1 &
                /bin/echo "Starting mural-server on port ${i}...${IPADDR}"
                sleep 5
        done

        for ((i=${MURAL_START_D};i<=${MURAL_FINISH_D};i++))
        do
                /usr/bin/nohup python webapp.py --port ${i} --model murals --type CNN --deviceid 3 >> ${LOGDIR}/mural-${i}.log 2>&1 &
                /bin/echo "Starting mural-server on port ${i}...${IPADDR}"
                sleep 5
        done


	
}


case "$1" in
     mural)
                startmural
        ;;
	killmural)
                killmural
        ;;
	*)
		/bin/echo "Usage: $0 {mural, killmural}"
			  exit 1
			  ;;
esac
*******************

3. >> cd /etc/nginx/sites-enabled
	i. Make new file: vi mural [to save & quit vi ":wq"]
   ii. These ports should be the same as the ones in /etc/init.d/imaging file

*******************
########## Filename: mural #########
upstream mural {
    least_conn;

    server 127.0.0.1:9000;
    server 127.0.0.1:9001;
    server 127.0.0.1:9002;
    server 127.0.0.1:9003;
    server 127.0.0.1:9004;
    server 127.0.0.1:9005;
    server 127.0.0.1:9006;
    server 127.0.0.1:9007;
    server 127.0.0.1:9008;
    server 127.0.0.1:9009;
    server 127.0.0.1:9010;
    server 127.0.0.1:9011;
    server 127.0.0.1:9012;
    server 127.0.0.1:9013;
    server 127.0.0.1:9014;
    server 127.0.0.1:9015;
    server 127.0.0.1:9016;
    server 127.0.0.1:9017;
    server 127.0.0.1:9018;
    server 127.0.0.1:9019;



}

server {
    server_name mural.ma.ggops.com;
    listen 8000;

    location / {
        proxy_pass http://mural;

    }
}
*******************

4. Start nginx 
	a. >> sudo service nginx stop
	b. >> sudo service nginx start
	c. >> sudo service nginx restart
5. Start nginx for mural
	a. >> sudo service imaging mural
6. Ways to check on whether all ports are up and running
	a. >> netstat -tpln 
	b. >> watch -n 0.1 "ps aux|grep webapp.py"
7. Way to check whether all gpu are being used
	a. >> watch -n 0.1 nvidia-smi
8. To stop the servers
	a. >> sudo service imaging killmural
9. Everytime you stop the servers - should make sure all ports are closed before relaunching.
10. Once all ports are up and running
	a. Can test from an outside machine: (port will be 8000 specified with nginx)
		- 54.174.14.18 is the ip of the machine
		>> curl -i "http://54.174.14.18:8000/?image=www.celebitchy.com/wp-content/uploads/2011/07/wenn3436540.jpg"
